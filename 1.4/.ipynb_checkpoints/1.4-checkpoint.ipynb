{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "silent-quilt",
   "metadata": {},
   "source": [
    "# CUDA编程模型---初识CUDA\n",
    "\n",
    "### 本次实验将介绍如何：\n",
    "1. 编写第一个Cuda程序\n",
    "2. 利用NVCC进行编译\n",
    "3. 编写Makefile文件\n",
    "4. 线程索引\n",
    "5. 利用nvprof查看程序性能"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-forest",
   "metadata": {},
   "source": [
    "----\n",
    "## 1.编写第一个Cuda程序\n",
    "- 关键词：\"\\_\\_global\\_\\_\" ,  <<<...>>>  ,  .cu\n",
    "\n",
    "在当前的目录下创建一个名为hello_cuda.cu的文件，编写第一个Cuda程序：\n",
    "- 当我们编写一个hello_word程序的时候，我们通常会这样写：\n",
    "```c\n",
    "    #include <stdio.h>\n",
    "\n",
    "    void hello_from_cpu()\n",
    "    {\n",
    "        printf(\"Hello World from the CPU!\\n\");\n",
    "    }\n",
    "\n",
    "    int main(void)\n",
    "    {\n",
    "        hello_from_cpu();\n",
    "        return 0;\n",
    "    }\n",
    "```\n",
    "\n",
    "- 如果我们要把它改成调用GPU的时候，我们需要在void hello_from_cpu()之前加入 \\_\\_global\\_\\_标识符，并且在调用这个函数的时候添加<<<...>>>来设定你需要多少个线程来执行这个函数\n",
    "- 在当前的目录下创建一个名为[hello_cuda.cu](hello_cuda.cu)的文件，更改上述程序，将它改为在GPU上执行的程序，如果遇到麻烦，请参考[result_1.cu](result_1.cu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-vermont",
   "metadata": {},
   "source": [
    "----\n",
    "## 2.编写完成之后，我们要开始编译并执行程序，在这里我们可以利用nvcc进行编译，指令如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aggressive-vampire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World from the GPU!\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc hello_cuda.cu -o hello_cuda -run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-eligibility",
   "metadata": {},
   "source": [
    "----\n",
    "## 3.这里我们也可以利用编写Makefile的方式来进行编译，一个简单的例子可以参考[Makefile](Makefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "grave-thomson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: 'hello_cuda' is up to date.\n"
     ]
    }
   ],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-suspension",
   "metadata": {},
   "source": [
    "然后我们就可以得到一个名为hello_cuda的程序，我们开始执行一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "amino-kuwait",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World from the GPU!\n"
     ]
    }
   ],
   "source": [
    "!./hello_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "matched-amount",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf ./hello_cuda\n",
      "rm -rf *.o\n"
     ]
    }
   ],
   "source": [
    "# clean output file\n",
    "!make clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-marking",
   "metadata": {},
   "source": [
    "接下来我们尝试多个文件协同编译, 修改[Makefile](Makefile)文件:\n",
    "1. 编译hello_from_gpu.cu文件生成hello_from_gpu.o\n",
    "2. 编译hello_cuda_01.cu和上一步生成的hello_from_gpu.o, 生成./hello_cuda_multi_file\n",
    "\n",
    "如果遇到麻烦, 请参考[Makefile_Multi_file](Makefile_Multi_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "empty-secretariat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda/bin/nvcc --device-c hello_from_gpu.cu -o hello_from_gpu.o\n",
      "/usr/local/cuda/bin/nvcc  hello_cuda_01.cu hello_from_gpu.o -o ./hello_cuda_multi_file\n"
     ]
    }
   ],
   "source": [
    "#此处通过-f来指定您使用的编译文件\n",
    "!make -f Makefile_Multi_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "disabled-receipt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World from the GPU!\n"
     ]
    }
   ],
   "source": [
    "!./hello_cuda_multi_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "complicated-fetish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf ./hello_cuda_multi_file\n",
      "rm -rf *.o\n"
     ]
    }
   ],
   "source": [
    "# clean output file\n",
    "!make -f Makefile_Multi_file clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-adams",
   "metadata": {},
   "source": [
    "这时，您已经完成了第一个Cuda程序，接下来修改<<<...>>>里面的信息，查看显示效果，如果遇到麻烦，请参考[hello_cuda_02.cu](hello_cuda_02.cu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-desperate",
   "metadata": {},
   "source": [
    "----\n",
    "## 4.线程索引\n",
    "当我们在讨论GPU和CUDA时，我们一定会考虑如何调用每一个线程，如何定为每一个线程。其实，在CUDA编程模型中，每一个线程都有一个唯一的标识符或者序号，而我们可以通过threadIdx来得到当前的线程在线程块中的序号,通过blockIdx来得到该线程所在的线程块在grid当中的序号，即：\n",
    "\n",
    "* **threadIdx.x** 是执行当前kernel函数的线程在block中的x方向的序号  \n",
    "\n",
    "* **blockIdx.x** 是执行当前kernel函数的线程所在block，在grid中的x方向的序号\n",
    "\n",
    "* **blockDim.x** 是执行当前kernel函数的线程所在的block在x方向包含多少个线程\n",
    "\n",
    "* **gridDim.x** 是执行当前kernel函数的grid在x方向包含多少个block\n",
    "\n",
    "\n",
    "接下来创建[Index_of_thread.cu](Index_of_thread.cu)文件，并在核函数中打印执行该核函数的线程编号和所在的线程块的编号，如果遇到麻烦，请参考[result_2.cu](result_2.cu)\n",
    "\n",
    "创建好了之后，我们开始编译"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "federal-preview",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <<<2, 4>>>\n",
    "!/usr/local/cuda/bin/nvcc Index_of_thread.cu -o Index_of_thread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-appointment",
   "metadata": {},
   "source": [
    "执行Index_of_thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "another-matrix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World from the GPU! blockIdx is 0, threadIdx is 0!\n",
      "Hello World from the GPU! blockIdx is 0, threadIdx is 1!\n",
      "Hello World from the GPU! blockIdx is 0, threadIdx is 2!\n",
      "Hello World from the GPU! blockIdx is 0, threadIdx is 3!\n",
      "Hello World from the GPU! blockIdx is 1, threadIdx is 0!\n",
      "Hello World from the GPU! blockIdx is 1, threadIdx is 1!\n",
      "Hello World from the GPU! blockIdx is 1, threadIdx is 2!\n",
      "Hello World from the GPU! blockIdx is 1, threadIdx is 3!\n"
     ]
    }
   ],
   "source": [
    "!./Index_of_thread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-stocks",
   "metadata": {},
   "source": [
    "修改`<<<...>>>`中的值，查看执行结果，这里建议分三组：`<<<33,5>>>`, `<<<5,33>>>`,`<<<5,65>>>`, 然后重新编译并执行， 前面是block num, 后面是 thread num in each block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "coastal-confusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <<<5, 2>>>\n",
    "!/usr/local/cuda/bin/nvcc Index_of_thread.cu -o Index_of_thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "greatest-energy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World from the GPU! blockIdx is 0, threadIdx is 0!\n",
      "Hello World from the GPU! blockIdx is 0, threadIdx is 1!\n",
      "Hello World from the GPU! blockIdx is 0, threadIdx is 2!\n",
      "Hello World from the GPU! blockIdx is 0, threadIdx is 3!\n",
      "Hello World from the GPU! blockIdx is 1, threadIdx is 0!\n",
      "Hello World from the GPU! blockIdx is 1, threadIdx is 1!\n",
      "Hello World from the GPU! blockIdx is 1, threadIdx is 2!\n",
      "Hello World from the GPU! blockIdx is 1, threadIdx is 3!\n"
     ]
    }
   ],
   "source": [
    "!./Index_of_thread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-kruger",
   "metadata": {},
   "source": [
    "----\n",
    "## 5.利用nvprof进行查看程序性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "unlikely-douglas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==22412== NVPROF is profiling process 22412, command: ./Index_of_thread\n",
      "==22412== Warning: Unified Memory Profiling is not supported on the underlying platform. System requirements for unified memory can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-requirements\n",
      "Hello World from the GPU! blockIdx is 0, threadIdx is 0!\n",
      "Hello World from the GPU! blockIdx is 0, threadIdx is 1!\n",
      "Hello World from the GPU! blockIdx is 0, threadIdx is 2!\n",
      "Hello World from the GPU! blockIdx is 0, threadIdx is 3!\n",
      "Hello World from the GPU! blockIdx is 1, threadIdx is 0!\n",
      "Hello World from the GPU! blockIdx is 1, threadIdx is 1!\n",
      "Hello World from the GPU! blockIdx is 1, threadIdx is 2!\n",
      "Hello World from the GPU! blockIdx is 1, threadIdx is 3!\n",
      "==22412== Profiling application: ./Index_of_thread\n",
      "==22412== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  95.245us         1  95.245us  95.245us  95.245us  hello_from_gpu(void)\n",
      "      API calls:   99.89%  313.38ms         1  313.38ms  313.38ms  313.38ms  cudaLaunchKernel\n",
      "                    0.07%  223.55us         1  223.55us  223.55us  223.55us  cudaDeviceSynchronize\n",
      "                    0.04%  113.24us        97  1.1670us     573ns  28.907us  cuDeviceGetAttribute\n",
      "                    0.00%  10.052us         1  10.052us  10.052us  10.052us  cuDeviceTotalMem\n",
      "                    0.00%  5.5730us         3  1.8570us  1.1980us  2.6560us  cuDeviceGetCount\n",
      "                    0.00%  3.0210us         2  1.5100us  1.3550us  1.6660us  cuDeviceGet\n",
      "                    0.00%  2.2920us         1  2.2920us  2.2920us  2.2920us  cuDeviceGetName\n",
      "                    0.00%     886ns         1     886ns     886ns     886ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "!sudo /usr/local/cuda/bin/nvprof  ./Index_of_thread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-perspective",
   "metadata": {},
   "source": [
    "- Profiling result：是GPU（kernel函数）上运行的时间\n",
    "- API calls：是在cpu上测量的程序调用API的时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "responsible-berkeley",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean output file\n",
    "!rm -f ./Index_of_thread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-medicaid",
   "metadata": {},
   "source": [
    "课后作业：\n",
    "1. 利用Makefile规则，尝试编写批量编译工具，比如：同时编译5个cuda程序。\n",
    "2. 利用Makefile规则，尝试加入链接库，比如：加入cuBLAS库编译cuda程序。\n",
    "3. 阅读Cuda sample code，尝试编写程序得到当前GPU的属性参数等。\n",
    "4. 阅读[nvprof](https://docs.nvidia.com/cuda/profiler-users-guide/index.html#nvprof-overview) 说明文档，了解更多nvprof的使用方法，为后续课程中使用做"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
