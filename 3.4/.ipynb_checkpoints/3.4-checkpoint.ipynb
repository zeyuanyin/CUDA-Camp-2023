{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e84a96ed",
   "metadata": {},
   "source": [
    "# CUDA编程模型---利用Shared Memory优化程序"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08afbd92",
   "metadata": {},
   "source": [
    "![](shared_memory.png)\n",
    "\n",
    "当我们在处理矩阵乘法时，假设矩阵M(m,k)\\*N(k,n) = P(m,n)。那么，矩阵M中的一个数值m(x,y),就要被grid中所有满足threadIdx.y+blockIdx.y\\*blockDim.y = y的线程从Global Memory中读一次，一共就是K次。那么，我们看到这么多重复读取，就可以把这个变量放在Shared Memory中，极大地减少每次的读取时间。我们可以按照下面的代码来修改martix_mul的核函数：\n",
    "\n",
    "```c\n",
    "__global__ void gpu_matrix(int* a, int* b, int* c, int m, int n, int k)\n",
    "{\n",
    "    __shared__ int sub_a[BLOCK_SIZE][BLOCK_SIZE];\n",
    "    __shared__ int sub_b[BLOCK_SIZE][BLOCK_SIZE];\n",
    "\n",
    "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "\n",
    "    int tmp =0;\n",
    "    int idx;\n",
    "    for(int step=0; step <= n/BLOCK_SIZE; step++)\n",
    "    {\n",
    "        int step_x = step * BLOCK_SIZE + threadIdx.x;\n",
    "        int step_y = y;\n",
    "        idx = step_y * n + step_x;\n",
    "        if(step_x >= n || step_y >= m)\n",
    "        {\n",
    "            sub_a[threadIdx.y][threadIdx.x] =0;\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            sub_a[threadIdx.y][threadIdx.x] = a[idx];\n",
    "        }\n",
    "\n",
    "        step_x = x;\n",
    "        step_y = step * BLOCK_SIZE + threadIdx.y;\n",
    "        idx = step_y * k +step_x;\n",
    "        if(step_x >= k || step_y >= n)\n",
    "        {\n",
    "            sub_b[threadIdx.y][threadIdx.x] = 0;\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            sub_b[threadIdx.y][threadIdx.x] = b[idx];\n",
    "        }\n",
    "\n",
    "        __syncthreads();\n",
    "\n",
    "        for(int i = 0; i < BLOCK_SIZE; i++)\n",
    "        {\n",
    "            tmp +=sub_a[threadIdx.y][i] * sub_b[i][threadIdx.x];\n",
    "        }\n",
    "        __syncthreads();\n",
    "    }\n",
    "\n",
    "    if ( x < k && y < m)\n",
    "    {\n",
    "        c[y*k + x] = tmp; \n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "修改[matrix_mul.cu](matrix_mul.cu)文件，编译并执行。如果遇到困难，请参考[result_1.cu](result_1.cu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720cd025",
   "metadata": {},
   "outputs": [],
   "source": [
    "!/usr/local/cuda/bin/nvcc matrix_mul.cu -o matrix_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1a7456",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./matrix_mul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01272330",
   "metadata": {},
   "source": [
    "课后作业:\n",
    "\n",
    "* 请大家尝试利用shared memory优化矩阵转置的示例, 如果遇到困难, 请参考[result_2.cu](result_2.cu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99c136a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
